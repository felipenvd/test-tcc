# ===================================================================
# CONFIGURAÇÃO DA REDE NEURAL - YOLOv4 CUSTOMIZADO
# Projeto: Detecção de Lesões e Perdas em Carcaças Bovinas
# Autores: Felipe e José Pires
# Dataset: 4 classes (lesões/perdas nos quartos dianteiro/traseiro)
# ===================================================================

[net]
# PARÂMETROS DE TREINAMENTO
batch=64                # Processa 64 imagens por iteração (otimizado para RTX 4050)
subdivisions=32         # Divide batch em 2 mini-batches de 32 (64/32=2) - melhor treinamento

# DIMENSÕES DAS IMAGENS DE ENTRADA
width=512               # Menor uso de GPU (treina mais rápido, boa precisão)
height=512              # Múltiplo de 32 (obrigatório para YOLO)
#width=608              # Padrão YOLOv4 (mais preciso mas usa mais GPU)
#height=608             # Opção original comentada
channels=3              # RGB (Red, Green, Blue) - imagens coloridas

# PARÂMETROS DO OTIMIZADOR
momentum=0.949          # Momentum SGD (suaviza oscilações no treinamento)
decay=0.0005           # Regularização L2 (previne overfitting)

# AUGMENTAÇÃO DE DADOS (melhora generalização)
angle=0                # Rotação das imagens (0 = sem rotação)
saturation = 1.5       # Varia saturação das cores (simula diferentes iluminações)
exposure = 1.5         # Varia exposição/brilho (simula condições de câmera)
hue=.1                 # Varia matiz das cores (simula diferentes temperaturas de cor)

# CRONOGRAMA DE APRENDIZADO
learning_rate=0.0001   # Taxa inicial de aprendizado (reduzido para estabilidade)
burn_in=200            # Primeiras 200 iterações com learning rate baixo (warm-up)
max_batches = 3000     # OTIMIZADO: Aumentado para 3000 iterações (1000 × 3 classes)
policy=steps           # Política de decaimento do learning rate por etapas
steps=2400,2700        # OTIMIZADO: Reduz LR em 80% (2400) e 90% (2700) do treinamento
scales=.1,.1           # Multiplica LR por 0.1 em cada step (reduz gradualmente)

# TÉCNICAS AVANÇADAS DE AUGMENTAÇÃO
#cutmix=1              # CutMix: mistura partes de imagens diferentes (desabilitado)
mosaic=0               # Mosaic: desabilitado para economizar GPU (pode reativar depois)

# ===================================================================
# INÍCIO DA ARQUITETURA CONVOLUCIONAL
# Backbone: Extrai características das imagens (bordas → texturas → objetos)
# ===================================================================

# PRIMEIRA CAMADA: Extrai bordas e características básicas
[convolutional]
batch_normalize=1       # Normalização (acelera convergência, estabiliza treinamento)
filters=32              # 32 filtros 3×3 (detectam bordas, linhas, curvas básicas)
size=3                  # Filtros 3×3 pixels (tamanho padrão para detecção de bordas)
stride=1                # Passo 1 (sem redução de tamanho: 608×608 → 608×608)
pad=1                   # Padding para manter dimensões (adiciona borda de 1 pixel)
activation=mish         # Mish > ReLU (melhor para gradientes, mais suave)

# DOWNSAMPLING: Reduz tamanho da imagem gradualmente (economiza memória)

[convolutional]
batch_normalize=1       # BatchNorm em todas as camadas conv (exceto antes de YOLO)
filters=64              # Dobra os filtros (32→64) à medida que reduz tamanho
size=3                  # Mantém filtros 3×3 (bom equilíbrio precisão/velocidade)
stride=2                # REDUZ TAMANHO: 608×608 → 304×304 (stride=2 é downsampling)
pad=1                   # Padding necessário para stride=2 funcionar corretamente
activation=mish         # Mish em todo o backbone (melhor que ReLU)

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers = -1,-7

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

# Downsample

[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=mish

[route]
layers = -1,-10

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

# Downsample

[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=mish

[route]
layers = -1,-28

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

# Downsample

[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear


[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=mish

[route]
layers = -1,-28

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

# Downsample

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=2
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[route]
layers = -2

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=mish

[shortcut]
from=-3
activation=linear

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=mish

[route]
layers = -1,-16

[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=1
activation=mish

##########################

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

### SPP ###
[maxpool]
stride=1
size=5

[route]
layers=-2

[maxpool]
stride=1
size=9

[route]
layers=-4

[maxpool]
stride=1
size=13

[route]
layers=-1,-3,-5,-6
### End SPP ###

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = 85

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1, -3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[upsample]
stride=2

[route]
layers = 54

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[route]
layers = -1, -3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky

##########################

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=256
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24              # CRÍTICO: (classes + 5) × 3 = (3 + 5) × 3 = 24 filtros
activation=linear       # Sem ativação (deixa valores "crus" para YOLO processar)

# ===================================================================
# PRIMEIRA CAMADA YOLO - DETECÇÃO EM ESCALA GRANDE (19×19)
# Detecta objetos GRANDES (lesões extensas, perdas grandes)
# ===================================================================
[yolo]
mask = 0,1,2           # Usa anchors 0, 1, 2 (os menores da lista)
# ANCHORS: "Chutes iniciais" de tamanhos típicos de objetos (largura, altura em pixels)
# Pequenos: (12,16) (19,36) (40,28) - para lesões pontuais
# Médios:   (36,75) (76,55) (72,146) - para lesões moderadas
# Grandes:  (142,110) (192,243) (459,401) - para perdas extensas
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=3              # CUSTOMIZADO: 3 classes do seu dataset bovino
num=9                  # Total de 9 anchors (3 por escala × 3 escalas)
jitter=.3              # Variação de posição para augmentação (30%)
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.2
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5


[route]
layers = -4

[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=256
activation=leaky

[route]
layers = -1, -16

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=512
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24              # CRÍTICO: Mesmo valor em todas as camadas YOLO
activation=linear       # Sem ativação (valores diretos para detecção)

# ===================================================================
# SEGUNDA CAMADA YOLO - DETECÇÃO EM ESCALA MÉDIA (38×38)
# Detecta objetos MÉDIOS (lesões moderadas, perdas médias)
# ===================================================================
[yolo]
mask = 3,4,5           # Usa anchors 3, 4, 5 (tamanhos médios)
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=3              # CUSTOMIZADO: Suas 3 classes de lesões/perdas
num=9                  # Sempre 9 anchors total
jitter=.3              # Mesma augmentação em todas as escalas
ignore_thresh = .7
truth_thresh = 1
scale_x_y = 1.1
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
nms_kind=greedynms
beta_nms=0.6
max_delta=5


[route]
layers = -4

[convolutional]
batch_normalize=1
size=3
stride=2
pad=1
filters=512
activation=leaky

[route]
layers = -1, -37

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=1
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=24              # CRÍTICO: Valor calculado para 3 classes
activation=linear       # Deixa YOLO decidir as detecções finais

# ===================================================================
# TERCEIRA CAMADA YOLO - DETECÇÃO EM ESCALA PEQUENA (76×76)
# Detecta objetos PEQUENOS (lesões pontuais, perdas menores)
# ===================================================================
[yolo]
mask = 6,7,8           # Usa anchors 6, 7, 8 (os maiores da lista)
anchors = 12, 16, 19, 36, 40, 28, 36, 75, 76, 55, 72, 146, 142, 110, 192, 243, 459, 401
classes=3              # CUSTOMIZADO: Lesão/Perda nos quartos dianteiro/traseiro
num=9                  # 9 anchors divididos em 3 escalas (3 cada)
jitter=.3              # Augmentação de posição (melhora generalização)
ignore_thresh = .7
truth_thresh = 1
random=0               # Desabilita redimensionamento dinâmico (economiza GPU)
scale_x_y = 1.05
iou_thresh=0.213
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou           # Complete IoU loss (melhor que IoU padrão)
nms_kind=greedynms      # Non-Maximum Suppression (remove detecções duplicadas)
beta_nms=0.6           # Parâmetro do NMS (agressividade na remoção)
max_delta=5            # Máxima mudança permitida nos anchors

# ===================================================================
# FIM DA CONFIGURAÇÃO YOLOv4 CUSTOMIZADO
#
# RESUMO DAS CUSTOMIZAÇÕES PARA CARCAÇAS BOVINAS:
# - classes: 80 → 4 (lesões/perdas nos quartos)
# - filters: 255 → 27 (fórmula: (4+5)×3)
# - max_batches: 500500 → 8000 (2000×4 classes)
# - steps: ajustados para 80% e 90% do treinamento
# - subdivisions: 16 (otimizado para RTX 4050)
#
# ARQUITETURA FINAL:
# Input: 608×608×3 → Backbone ConvNet → 3 escalas YOLO → Output: detecções
#
# Para modificar este arquivo:
# 1. Mantenha sempre: filters = (classes + 5) × 3
# 2. Ajuste max_batches para: 2000 × número_de_classes
# 3. Configure steps para 80% e 90% do max_batches
# 4. Use subdivisions múltiplo de batch para economizar GPU
#
# Autores: Felipe e José Pires | TCC 2025
# ===================================================================